{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dcef6c",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "Note: additional python packages may need to be installed in your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec838e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import array\n",
    "import datetime\n",
    "import time\n",
    "import requests as req\n",
    "\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "from sqlalchemy.engine import URL, create_engine\n",
    "\n",
    "from IPython.display import clear_output\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e0874c",
   "metadata": {},
   "source": [
    "# Functions for Event Processing\n",
    "The event processing uses the following steps:\n",
    "1. reduce_columns: takes a dataframe and reduces it to only the necessary columns\n",
    "2. group_data: groups points on a dataframe into an energy level and a duration\n",
    "3. smooth_data: smooths out data to produce a dataframe where the lifetimeEnergy is always increasing\n",
    "4. calculate_events: calculates events using a dataframe where hte lifetimeEnergy is always increasing\n",
    "5. data_quality_check: indicates how much energy was captured in the event definition\n",
    "6. data_qualiy_control: adds in unaccounted for energy into events\n",
    "7. adjust_time: corrects the timezone\n",
    "8. add_meter_ids: adds in the meterIds based on a fetch_list or other lookup table\n",
    "\n",
    "Of these, the smooth_data, and calculate_events are the most complex/critical and the others are simple helper functions.\n",
    "\n",
    "The smooth_data function operates with the understanding that the lifetimeEnergy values from the smart meters should *always* be increasing (this is true after grouping datapoints with the same lifetimeEnergy value into a single datapoint). The function extracts and orders the unique lifetimeEnergy values from a dataframe. Then, it searches the dataframe for datapoints where the lifetimeEnergy value is out of order and corrects the value based on the neighboring values and expected values from the ordered list. It iterates through this process, expected to take less than 10 iterations for a given meter.\n",
    "\n",
    "The calculate_events function takes a dataset and identifies the starts and ends of events based on a time duration criteria (default 15 minutes). In the most basic case, if the lifetimeEnergy does not increase for the specified duration then that datapoint signals the start and the end of an event. Additionally, a gap between datapoints of more than the specified duration would also signal an event start and end. More nuance is added to address situations where multiple datapoints in a row meet the criteria for an event start or end.\n",
    "\n",
    "There are likely ways to improve the efficiency and clarity of these two functions, such as by refining both functions to involve fewer specific criteria (\"if it looks like this, this should happen\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222839bc",
   "metadata": {},
   "source": [
    "### Basic Instructions (tl;dr):\n",
    "1. Run all of the following cells to define the functions\n",
    "2. Go to the \"Try it Out\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f066e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_columns(df):\n",
    "    df = df.loc[:, (\"account_id\", \"time\", \"lifetimeEnergy\")]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(df, raw = True):\n",
    "    \"\"\"\n",
    "    This function is for grouping data according to the lifetimeEnergy. For \"raw\" data, it does an additional sorting step\n",
    "    and then aggregates the time column, which is then renamed to measurementTime_min and _max columns. The raw == False\n",
    "    loop is used in the smoothing function for data that has already been grouped before.\n",
    "    \"\"\"\n",
    "    if raw == True:\n",
    "        clear_output(wait=True)\n",
    "        print(\"Grouping data...\")\n",
    "        # sort the data by the account and then the measurement time\n",
    "        df = df.sort_values(['account_id','time']).fillna(method = 'ffill').reset_index()\n",
    "    \n",
    "        # Add a column that enables us to group consecutive rows. This is later used in the smoothing \n",
    "        # function as it allows us to differentiate groups of the same lifetimeEnergy values.\n",
    "        df[\"grouping\"] = df[\"lifetimeEnergy\"].diff().ne(0).cumsum()\n",
    "    \n",
    "        # Then group the data to simplify it into a new structure: start, end, energy value\n",
    "        df = df.groupby([\"account_id\", \"grouping\", \"lifetimeEnergy\"], as_index=False)\\\n",
    "        .aggregate(measurementTime_min = ('time', 'min'),\n",
    "                   measurementTime_max = ('time', 'max'),\n",
    "                  )\n",
    "        \n",
    "    else:\n",
    "        # add a column that enables us to group consecutive rows\n",
    "        df[\"grouping\"] = df[\"lifetimeEnergy\"].diff().ne(0).cumsum()\n",
    "\n",
    "        df = df.groupby([\"account_id\", \"grouping\", \"lifetimeEnergy\"], as_index=False)\\\n",
    "        .aggregate(measurementTime_min = ('measurementTime_min', 'min'),\n",
    "                   measurementTime_max = ('measurementTime_max', 'max'),\n",
    "                  )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(df, col = \"lifetimeEnergy\"):\n",
    "    \"\"\"\n",
    "    This function smooths smart meter data so that it is monotonically (always) increasing. \n",
    "    It consists of a smoothing function called smoother and two loops.\n",
    "    \n",
    "    This function is much more complicated than intended. However, after resolving back-end issues, it effects very little.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def smoother(df, col):\n",
    "        \"\"\"\n",
    "        First step: create columns to help identify where the data needs to be corrected\n",
    "        \n",
    "        pv_e: the lifetimeEnergy value that is expected to preced the current datapoint\n",
    "        fv_e: the lifetimeEnergy value that is expected to follow the current datapoint\n",
    "        pv: 0 if the preceding lifetimeEnergy value is incorrect, 1 if it is correct\n",
    "        fv: 0 if the following lifetimeEnergy value is incorrect, 1 if it is correct\n",
    "        ev: a single digit representation of whether a point is ordered correctly based on the preceding and following values\n",
    "        \"\"\"\n",
    "        # Create a temporary column used to store updated values\n",
    "        df[\"temp\"] = df[col]\n",
    "        \n",
    "        # Create an ordered list of the unique energy values\n",
    "        # For easy access, add two columns stating the expected preceding and following values (pv_e and fv_e)\n",
    "        y_ordered = df.loc[:, [col]].sort_values(col).drop_duplicates()\n",
    "        y_ordered[\"pv_e\"] = y_ordered[\"lifetimeEnergy\"].shift(1)\n",
    "        y_ordered[\"fv_e\"] = y_ordered[\"lifetimeEnergy\"].shift(-1)\n",
    "        \n",
    "        # Merge the dataframe with the ordered values\n",
    "        df = df.merge(y_ordered, left_on = col, right_on = col).sort_values(by = 'grouping')\n",
    "        \n",
    "        # Create a mask for rows where the expected preceding value matches the actual preceding value\n",
    "        # Set pv = 1 if the preceding value is as expected based on the ordered list\n",
    "        mask_pv = df[\"pv_e\"] == df[col].shift(1)\n",
    "        df[\"pv\"] = 0\n",
    "        df[\"pv\"] = df[\"pv\"].mask(mask_pv, 1)\n",
    "        \n",
    "        # Create a mask for rows where the expected following value matches the actual following value\n",
    "        # Set fv = 2 if the following value is as expected based on the ordered list\n",
    "        mask_fv = df[\"fv_e\"] == df[col].shift(-1)\n",
    "        df[\"fv\"] = 0\n",
    "        df[\"fv\"] = df[\"fv\"].mask(mask_fv, 2)\n",
    "        \n",
    "        # Create a new column for the \"expected value\"\n",
    "        # 0: both the preceding and following values are incorrect\n",
    "        # 1: only the preceding value is correct\n",
    "        # 2: only the following value is correct\n",
    "        # 3: both the preceding and following values are correct\n",
    "        df[\"ev\"] = df[\"pv\"]+df[\"fv\"]\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Step 2: Correct the incorrectly ordered points based on the surrounding datapoints.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Find the places where:\n",
    "        # 1: the preceding row has a correct preceding value but incorrect following value (ev == 1)\n",
    "        # 2: and where the following row has a correct following value but incorrect preceding value (ev == 2)\n",
    "        # 3: and where the following row has a value greater than or equal to the value of the preceding row\n",
    "        #\n",
    "        # Set the lifetimeEnergy value to be the average of the preceding and following lifetimeEnergy values.\n",
    "        #\n",
    "        # ex: Evaluating the third value in this series (lifetimeEnergy == 10)\n",
    "        # lifetimeEnergy:    [12, 13, 10, 14, 15]  goes to [12, 13, 13.5, 14, 15]\n",
    "        #             ev:    (x,   1,  0,  2,  x)\n",
    "        df[\"temp\"].loc[(df[\"ev\"].shift(1) == 1) & (df[\"ev\"].shift(-1) == 2) & (df[col].shift(-1) >= df[col].shift(1))\n",
    "                      ] = (df[\"lifetimeEnergy\"].shift(1) + df[\"lifetimeEnergy\"].shift(-1)) / 2\n",
    "        \n",
    "        \n",
    "        # If the third condition above is false (i.e. its a downward slope), instead change the preceding and \n",
    "        # following rows and set them to be equal to the their preceding/following rows\n",
    "        #\n",
    "        # ex: evaluating the second value in this series (lifetimeEnergy == 13) and the fourth value (lifetimeEnergy == 12) \n",
    "        #     [12, 13, 10, 12, 13] goes to [12, 12, 10, 13, 13] which is resolved on the next Iteration\n",
    "        #     ( x,  1,  2,  3,  x)\n",
    "        #\n",
    "        # adjusting the second value\n",
    "        df[\"temp\"].loc[(df[\"ev\"] == 1) & (df[\"ev\"].shift(-2) == 2) & (df[col].shift(-2) < df[col])\n",
    "                      ] = df[col].shift(1)\n",
    "        # adjusting the fourth value\n",
    "        df[\"temp\"].loc[(df[\"ev\"].shift(2) == 1) & (df[\"ev\"] == 2) & (df[col] < df[col].shift(2))\n",
    "                      ] = df[col].shift(-1)\n",
    "        \n",
    "        \n",
    "        # Find the places where:\n",
    "        # 1: the current row has a correct preceding value but incorrect following value (ev == 1)\n",
    "        # 2: the following row has a correct following value but incorrect preceding value (ev == 2)\n",
    "        #\n",
    "        # Assign the value of the current row to the value preceding it, and\n",
    "        # assign the value of the following row to the one following that one\n",
    "        # ex: [12, 13, 12, 13] goes to [12, 12, 13, 13]\n",
    "        #     ( x,  1,  2,  x)\n",
    "        df[\"temp\"].loc[(df[\"ev\"] == 1) & (df[\"ev\"].shift(-1) == 2)\n",
    "                      ] = df[col].shift(1)\n",
    "        df[\"temp\"].loc[(df[\"ev\"] == 2) & (df[\"ev\"].shift(1) == 1)\n",
    "                      ] = df[col].shift(-1)\n",
    "        \n",
    "        # Find the places where:\n",
    "        # 1: the preceding row has both incorrect preceding and following values (ev == 1)\n",
    "        # 2: the preceding row has a correct preceding value but incorrect following value (ev == 0)\n",
    "        # 3: the following row has incorrect preceding and following values (ev == 0)\n",
    "        #\n",
    "        # Set the current row to the expected following value of the preceding row\n",
    "        # ex: [12, 13, 17, 12, 14] goes to [12, 13, 14, 12, 14] \n",
    "        #     ( x,  1,  0,  0,  x)         ( x,  3,  1,  0,  x)\n",
    "        df[\"temp\"].loc[(df[\"ev\"] == 0) & (df[\"ev\"].shift(1) == 1) & (df[\"ev\"].shift(-1) == 0)\n",
    "                      ] = df[\"fv_e\"].shift(1)\n",
    "        \n",
    "        # Find the places where:\n",
    "        # 1: the preceding row has both incorrect preceding and following values (ev == 0)\n",
    "        # 2: the current row has incorrect preceding and following values (ev == 0)\n",
    "        # 3: the following row has a correct following value but incorrect preceding value (ev == 2)\n",
    "        #\n",
    "        # Set the current row to the preceding value that is expected from the following row\n",
    "        # ex: [12, 11, 17, 13, 14] goes to [12, 11, 12, 13, 14] \n",
    "        #     ( x,  0,  0,  2,  x)         ( x,  2,  3,  3,  x)\n",
    "        df[\"temp\"].loc[(df[\"ev\"] == 0) & (df[\"ev\"].shift(1) == 0) & (df[\"ev\"].shift(-1) == 2)\n",
    "                      ] = df[\"pv_e\"].shift(-1)\n",
    "        \n",
    "        # Find the places where:\n",
    "        # 1: the preceding row has a correct preceding value but incorrect following value (ev ==1 )\n",
    "        # 2: the current row has incorrect preceding and following values (ev == 0)\n",
    "        # 3: the following row and preceding rows have the same lifetimeEnergy values\n",
    "        #\n",
    "        # Set the current row to the value before/after\n",
    "        # ex: [12, 13, 17, 13, 14] goes to [12, 13, 13, 18, 13]\n",
    "        #     (x,   1,  3,  x,  x) \n",
    "        df[\"temp\"].loc[(df[\"ev\"].shift(2) == 3) & (df[\"ev\"].shift(1) == 1) & (df[col].shift(1) == df[col].shift(-1))\n",
    "                      ] = df[col].shift(1)\n",
    "        \n",
    "        # Round the values to two decimal points\n",
    "        df[col] = df[\"temp\"].round(2)\n",
    "        \n",
    "        # Fix the first and last values\n",
    "        df[col].iat[0] = df[col].min()\n",
    "        df[col].iat[-1] = df[col].max()\n",
    "        \n",
    "        df = group_data(df, raw = False)\n",
    "        return df\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    # Main loop for running the smoother for each meter\n",
    "    # m: variable just for tracking how many meters have been completed\n",
    "    # i: variable for tracking iterations. Passes into the smoother function\n",
    "    m = 0\n",
    "    for account in df[\"account_id\"].unique():\n",
    "        m = m+1\n",
    "        i = 1\n",
    "        \n",
    "        # First pull the data from an individual meter\n",
    "        df_i = df.loc[df[\"account_id\"] == account]\n",
    "        \n",
    "        # The main loop for iterating through each meter\n",
    "        # The .is_monotonic_increasing function results in the need for iterating through meters individually\n",
    "        while df_i[col].is_monotonic_increasing == False:\n",
    "            # run the smoothing function\n",
    "            df_i = smoother(df_i, col)\n",
    "            \n",
    "            # update progress and timeout as necessary\n",
    "            clear_output(wait=True)\n",
    "            print(\"Processing account ID \" + str(account) + \", estimated progress = \" + str(round(100 * (m-1) / len(df[\"account_id\"].unique()),2)) + \"%\")\n",
    "            i = i + 1\n",
    "            if i == 50:\n",
    "                print(\"Error: timeout\")\n",
    "                return df_i\n",
    "        \n",
    "        # add the individual meter's smoothed data to the output\n",
    "        print(\"Concatenating Data\")\n",
    "        df_out = pd.concat([df_out, df_i])\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e03508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_events(df, ycol=\"lifetimeEnergy\", minutes = 15, strict = \"on\"):\n",
    "    clear_output(wait=True)\n",
    "    print(\"Calculating events...\")\n",
    "    \"\"\"\n",
    "    Calculate the time difference between points\n",
    "    Just group by the meter & energy and aggregate time\n",
    "    If the time at a given value is greater than the minutes variable, then remove those values, but keep the head and tail\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate the difference in time between subsequent datapoints\n",
    "    df['measurementTime_min'] = pd.to_datetime(df['measurementTime_min'])\n",
    "    df['measurementTime_max'] = pd.to_datetime(df['measurementTime_max'])\n",
    "    \n",
    "    # the 'backward' time difference is the difference between a datapoint and the previous one\n",
    "    # the backward time difference signals the start of an event: more than 15 minutes have passed since the last value\n",
    "    df[\"time_diff_b\"] = df['measurementTime_min'] - df['measurementTime_max'].shift(1, fill_value = df['measurementTime_max'].min() - timedelta(minutes=100))\n",
    "    df[\"time_diff_b\"].loc[df[\"account_id\"] != df[\"account_id\"].shift(1)] = timedelta(minutes=100)\n",
    "    df[\"time_diff_b\"] = df[\"time_diff_b\"] / timedelta(minutes=1)\n",
    "    #return df\n",
    "    \n",
    "    # the 'forward' time difference is the difference between a datapoint and the following value\n",
    "    # this signals the end of a cooking event\n",
    "    df[\"time_diff_f\"] = df['measurementTime_min'].shift(-1, fill_value = df['measurementTime_min'].max() + timedelta(minutes=100)) - df['measurementTime_max']\n",
    "    df[\"time_diff_f\"].loc[df[\"account_id\"] != df[\"account_id\"].shift(-1)] = timedelta(minutes=100)\n",
    "    df[\"time_diff_f\"] =  df[\"time_diff_f\"] / timedelta(minutes=1)\n",
    "    \n",
    "    df[\"duration\"] = df['measurementTime_max'] - df['measurementTime_min']\n",
    "    df[\"duration\"] = df[\"duration\"] / timedelta(minutes=1)\n",
    "\n",
    "    # group the data: find the highest and lowest measurement times at each energy value per meter\n",
    "    # and sum the forward and backward differences\n",
    "    df_group = df.groupby([\"account_id\", ycol], as_index=False).aggregate(measurementTime_min = ('measurementTime_min', 'min'),\n",
    "                                                              measurementTime_max = ('measurementTime_max', 'max'),\n",
    "                                                              time_diff_b = ('time_diff_b', 'sum'),\n",
    "                                                              time_diff_f = ('time_diff_f', 'sum'),\n",
    "                                                                          duration = (\"duration\", 'sum')\n",
    "                                                             )\n",
    "    \n",
    "    #return df_group\n",
    "    \n",
    "    # Find all the areas where the events start and end\n",
    "    # Reminder: Events start when the backward time difference is more than the cut-off (default 15)\n",
    "    # Exclude rows where there is a start and end and the following row has a start\n",
    "    # Also exclude rows where the duration is more than the cut-off (default 15) and the following row has a start\n",
    "    #\n",
    "    # The strict parameter includes an extra condition to consider points where the duration is more than minutes parameter\n",
    "    # Strict is mainly relevant when the sampling frequency (e.g. 10 minutes) is large relative to the event cut-off (e.g. 15 minutes)\n",
    "    # Example use-case for \"strict\":\n",
    "    # 9:10 - 95.34\n",
    "    # 9:20 - 95.36\n",
    "    # 9:30 - 95.39\n",
    "    # 9:40 - 95.39\n",
    "    # 9:50 - 95.42\n",
    "    # 10:00 - 95.42\n",
    "    # 10:10 - 95.42\n",
    "    # In this case, it is unclear whether the increase from 95.39 to 95.42 happened between 9:40 to 9:45 or between 9:45 to 9:50\n",
    "    # If strict == on, this would be considered as 2 events (event 1: start = 9:10 and end = 9:30, event 2: start = 9:40 and end = 9:50) \n",
    "    # If strict == off, this would be considered as 1 event (event 1: start = 9:10 and end = 9:50)\n",
    "    if (strict == \"on\"):\n",
    "        df_event_start = df_group.loc[((df_group[\"time_diff_b\"] >= minutes) & (df_group[\"time_diff_f\"] < minutes)) |\n",
    "                                      ((df_group[\"time_diff_b\"] >= minutes) & (df_group[\"time_diff_f\"] >= minutes) & (df_group[\"time_diff_b\"].shift(-1) < minutes)) |\n",
    "                                      ((df_group[\"duration\"] >= minutes) & (df_group[\"time_diff_b\"].shift(-1) < minutes)) |\n",
    "                                      (((df_group[\"time_diff_b\"] + df_group[\"duration\"]) >= minutes) & ((df_group[\"time_diff_f\"] + df_group[\"duration\"]) >= minutes) & (df_group[\"time_diff_b\"].shift(-1) < minutes))\n",
    "                                     ].loc[:, ['account_id', 'measurementTime_max', 'lifetimeEnergy']]\n",
    "    else:\n",
    "        df_event_start = df_group.loc[((df_group[\"time_diff_b\"] >= minutes) & (df_group[\"time_diff_f\"] < minutes)) |\n",
    "                                      ((df_group[\"time_diff_b\"] >= minutes) & (df_group[\"time_diff_f\"] >= minutes) & (df_group[\"time_diff_b\"].shift(-1) < minutes)) |\n",
    "                                      ((df_group[\"duration\"] >= minutes) & (df_group[\"time_diff_b\"].shift(-1) < minutes))\n",
    "                                     ].loc[:, ['account_id', 'measurementTime_max', 'lifetimeEnergy']]\n",
    "    \n",
    "    # rename the columns\n",
    "    df_event_start = df_event_start.rename(columns = {\"measurementTime_max\": \"event_time_start\",\n",
    "                                                      \"lifetimeEnergy\": \"event_energy_start\"\n",
    "                                                     })\n",
    "    # do the same for the event ends\n",
    "    if (strict == \"on\"):\n",
    "        df_event_end = df_group.loc[((df_group[\"time_diff_b\"] < minutes) & (df_group[\"time_diff_f\"] >= minutes)) |\n",
    "                                    ((df_group[\"time_diff_b\"] >= minutes) & (df_group[\"time_diff_f\"] >= minutes) & (df_group[\"time_diff_f\"].shift(1) < minutes)) | \n",
    "                                    ((df_group[\"duration\"] >= minutes) & (df_group[\"time_diff_f\"].shift(1) < minutes)) |\n",
    "                                    (((df_group[\"time_diff_b\"] + df_group[\"duration\"]) >= minutes) & ((df_group[\"time_diff_f\"] + df_group[\"duration\"]) >= minutes) & (df_group[\"time_diff_f\"].shift(1) < minutes))\n",
    "                                   ].loc[:, ['measurementTime_min', 'lifetimeEnergy']]\n",
    "    else:\n",
    "        df_event_end = df_group.loc[((df_group[\"time_diff_b\"] < minutes) & (df_group[\"time_diff_f\"] >= minutes)) |\n",
    "                                    ((df_group[\"time_diff_b\"] >= minutes) & (df_group[\"time_diff_f\"] >= minutes) & (df_group[\"time_diff_f\"].shift(1) < minutes)) | \n",
    "                                    ((df_group[\"duration\"] >= minutes) & (df_group[\"time_diff_f\"].shift(1) < minutes))\n",
    "                                   ].loc[:, ['measurementTime_min', 'lifetimeEnergy']]\n",
    "        \n",
    "    df_event_end = df_event_end.rename(columns = {\"measurementTime_min\": \"event_time_end\",\n",
    "                                                  \"lifetimeEnergy\": \"event_energy_end\"\n",
    "                                                     })\n",
    "    \n",
    "    # add these into a new dataframe, drop the indexes\n",
    "    df_events = pd.concat([df_event_start.reset_index(drop = True), df_event_end.reset_index(drop = True)], axis = 1)\n",
    "    \n",
    "    # add two new columns: event energy and event time and calculate the values\n",
    "    df_events.insert(loc = len(df_events.columns), column = \"event_energy\", value = df_events[\"event_energy_end\"] - df_events[\"event_energy_start\"])\n",
    "    df_events.insert(loc = len(df_events.columns), column = \"event_time\", value = df_events[\"event_time_end\"] - df_events[\"event_time_start\"])\n",
    "    df_events.insert(loc = len(df_events.columns), column = \"event_time_h\", value = df_events[\"event_time\"] / timedelta(hours=1))\n",
    "    df_events.insert(loc = len(df_events.columns), column = \"event_power_kW\", value = df_events[\"event_energy\"] / df_events[\"event_time_h\"])\n",
    "    \n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    return df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_check(df_i):\n",
    "    \"\"\"\n",
    "    A tool for checking quality of data based on the event grouping\n",
    "    df_events: the processed data set with the events\n",
    "    \"\"\"\n",
    "    clear_output(wait=True)\n",
    "    print(\"Checking quality...\")\n",
    "    df = df_i.copy()\n",
    "    \n",
    "    # Find the difference between the energy recorded at the end of the event and the energy recorded at the start of the next\n",
    "    df[\"unaccounted_energy\"] = df[\"event_energy_start\"].shift(-1) - df[\"event_energy_end\"]\n",
    "    df[\"unaccounted_energy\"].loc[df[\"account_id\"] != df[\"account_id\"].shift(-1)] = 0\n",
    "    \n",
    "    # Aggregate the data. Find the minimum and maximum recorded event energy for each meter and the sum of the missing energy\n",
    "    df_q = df.groupby([\"account_id\"], as_index=False).aggregate(energy_min = (\"event_energy_start\", 'min'),\n",
    "                                                                energy_max = (\"event_energy_end\", 'max'),\n",
    "                                                                unaccounted_energy = (\"unaccounted_energy\", 'sum')\n",
    "                                                               )\n",
    "    \n",
    "    # Compare the missing energy to the total energy\n",
    "    df_q[\"quality\"] = 1 - (df_q[\"unaccounted_energy\"] / (df_q[\"energy_max\"] - df_q[\"energy_min\"]))\n",
    "    df_q[\"quality\"] = df_q[\"quality\"].round(2)\n",
    "    \n",
    "    recorded_energy_total = round(df_q[\"energy_max\"].sum() - df_q[\"energy_min\"].sum(), 2)\n",
    "    unaccounted_energy_total = round(df_q[\"unaccounted_energy\"].sum(), 2)\n",
    "    q_tot = round(100 - (unaccounted_energy_total * 100 / recorded_energy_total), 2)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"Total recorded energy = \"+str(recorded_energy_total) + \". Unaccounted energy = \" + str(unaccounted_energy_total) + \". \" + str(q_tot) + \"% of energy accounted for in events.\")\n",
    "    return df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81123a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_control(df_i, mode = \"split\", limit = 1.0):\n",
    "    \"\"\"\n",
    "    A simple script for correcting the event definitions. Due to the way the meters function and are used in the field,\n",
    "    there is often energy that occurs between the meter's save points. This is because the meters are continuously\n",
    "    counting energ but only periodically save datapoints.\n",
    "    \n",
    "    When a meter is powered off (very common in cooking projects), the meter will have counted the energy used until \n",
    "    it was powered off but may not have saved the count as a datapoint. When the meter is powered back on, it resumes counting\n",
    "    from where it left off but still may take several minutes to save its count as a new datapoint. Thus the energy count\n",
    "    is accurate, but the timing of the usage is unclear.\n",
    "    \n",
    "    Example: An appliance uses 600W of continuous power and is connected to a meter that saves data every 10 mintues.\n",
    "    At 9:00AM, the meter count is 200.00 kWh. The meter saves this datapoint.\n",
    "    At 9:06AM, the meter count is 200.06 kWh. The meter is powered off.\n",
    "    At 4:00:01PM, the meter is reconnected to power. The meter count resumes at 200.06 kWh.\n",
    "    At 4:10PM, the meter count is 200.16 kWh. The meter saves this datapoint. \n",
    "    The datapoints will read:\n",
    "    9:00AM: 200.00 kWh\n",
    "    4:10PM: 200.16 kWh\n",
    "    Thus the data shows an energy increase of 0.16 happening sometime during a 7 hour period. When processing this example\n",
    "    as an event, one event would end at 9:00 AM and 200.00 kWh (the last recorded datapoint before a long gap) and the next\n",
    "    event would start at 4:10PM and 200.16kWh (the first recorded datapoint after a long gap).\n",
    "    This script corrects this by adding the 0.16 kWh of unaccounted energy back into the events. It also adjusts the times\n",
    "    accordingly.\n",
    "    \n",
    "    Four modes of correction:\n",
    "        conservative: the unaccounted energy is not included in any events (nothing happens!)\n",
    "        trailing: the unaccounted energy is added to the preceding event (meter counts after saving)\n",
    "        leading: the unaccounted energy is added to the following event (meter counts before saving)\n",
    "        split: the unaccounted energy is split evenly between the preceding and following events\n",
    "        \n",
    "    limit:     energy gaps larger than the limit will be ignored and not corrected\n",
    "    \n",
    "    \"\"\"\n",
    "    df = df_i.copy()\n",
    "    print(\"Events corrected. Mode = \" + mode)\n",
    "    \n",
    "    if mode == \"conservative\":\n",
    "        return df\n",
    "    \n",
    "    # Find the difference between the energy recorded at the end of the event and the energy recorded at the start of the next\n",
    "    df[\"unaccounted_energy\"] = df[\"event_energy_start\"].shift(-1) - df[\"event_energy_end\"]\n",
    "    df[\"unaccounted_energy\"].loc[df[\"account_id\"] != df[\"account_id\"].shift(-1)] = 0\n",
    "    df[\"unaccounted_energy\"].loc[df[\"unaccounted_energy\"] > limit] = 0\n",
    "    \n",
    "    # Add a column for calculating the power in each event\n",
    "    df[\"power\"] = df[\"event_energy\"] / (df[\"event_time\"] / timedelta(hours=1))\n",
    "    \n",
    "    if mode == \"trailing\":\n",
    "        df[\"event_energy_end\"] = df[\"event_energy_end\"] + df[\"unaccounted_energy\"]\n",
    "        df[\"event_time_end\"] = df[\"event_time_end\"] + ((df[\"unaccounted_energy\"] / df[\"power\"]) * timedelta(hours=1))\n",
    "    elif mode == \"leading\":\n",
    "        df[\"event_energy_start\"] = df[\"event_energy_start\"] - df[\"unaccounted_energy\"].shift(1, fill_value = 0)\n",
    "        df[\"event_time_start\"] = df[\"event_time_start\"] - ((df[\"unaccounted_energy\"].shift(1, fill_value = 0) / df[\"power\"]) * timedelta(hours=1))\n",
    "    else:\n",
    "        df[\"event_energy_end\"] = df[\"event_energy_end\"] + (df[\"unaccounted_energy\"] / 2)\n",
    "        df[\"event_energy_start\"] = df[\"event_energy_start\"] - (df[\"unaccounted_energy\"].shift(1, fill_value = 0) / 2)\n",
    "        \n",
    "        df[\"event_time_end\"] = df[\"event_time_end\"] + (((df[\"unaccounted_energy\"] / 2) / df[\"power\"]) * timedelta(hours=1))\n",
    "        df[\"event_time_start\"] = df[\"event_time_start\"] - (((df[\"unaccounted_energy\"].shift(1, fill_value = 0) / 2) / df[\"power\"]) * timedelta(hours=1))\n",
    "    \n",
    "    \n",
    "    df[\"event_energy\"] = df[\"event_energy_end\"] - df[\"event_energy_start\"]\n",
    "    df[\"event_time_start\"] = df[\"event_time_start\"].dt.round(\"min\")\n",
    "    df[\"event_time_end\"] = df[\"event_time_end\"].dt.round(\"min\")\n",
    "    df[\"event_time\"] = df[\"event_time_end\"] - df[\"event_time_start\"]\n",
    "    \n",
    "    #df[\"power_2\"] = df[\"event_energy\"] / (df[\"event_time\"] / timedelta(hours=1))\n",
    "    df = df.drop(columns = [\"unaccounted_energy\", \"power\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_time(df_i, hours = 0):\n",
    "    df = df_i.copy()\n",
    "    df[\"event_time_start\"] = df[\"event_time_start\"] + timedelta(hours = hours)\n",
    "    df[\"event_time_end\"] = df[\"event_time_end\"] + timedelta(hours = hours)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meterIds(df_i, df_lookup):\n",
    "    \"\"\"\n",
    "    For adding the meterIds back into the events list\n",
    "    Both dataframes must have columns named meterId and account_id\n",
    "    \"\"\"\n",
    "    df = df_i.copy()\n",
    "    df.insert(loc = 1, column = \"meterId\", value = df[\"account_id\"])\n",
    "    \n",
    "    df[\"meterId\"] = df[\"meterId\"].replace(dict(zip(df_lookup[\"account_id\"], df_lookup[\"meterId\"])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed759f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_otherCol(df_i, df_lookup, col):\n",
    "    \"\"\"\n",
    "    For adding the meterIds back into the events list\n",
    "    Both dataframes must have columns named meterId and account_id\n",
    "    \"\"\"\n",
    "    df = df_i.copy()\n",
    "    df.insert(loc = 1, column = col, value = df[\"account_id\"])\n",
    "    \n",
    "    df[col] = df[col].replace(dict(zip(df_lookup[\"account_id\"], df_lookup[col])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e43663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_events(df_i, filter_type = 'time', condition = 'below', filter_val = '00:01:00'):\n",
    "    \"\"\"\n",
    "    Filter out the events based on criteria provided.\n",
    "    \n",
    "    filter_type should be either:\n",
    "    1. time\n",
    "    2. energy\n",
    "    3. power\n",
    "    \n",
    "    condition should be either:\n",
    "    1. above\n",
    "    2. below\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df_i.copy()\n",
    "    \n",
    "    if filter_type == 'time':\n",
    "        col = \"event_time\"\n",
    "    elif filter_type == 'energy':\n",
    "        col = 'event_energy'\n",
    "        filter_val = float(filter_val)\n",
    "    elif filter_type == 'power':\n",
    "        col = 'event_power'\n",
    "        filter_val = float(filter_val)\n",
    "        if col not in df.columns:\n",
    "            df.insert(loc = len(df.columns), column = col, value = df[\"event_energy\"] / (df[\"event_time\"] / timedelta(hours=1)))\n",
    "    elif filter_type == 'date':\n",
    "        col = 'event_time_start'\n",
    "    \n",
    "    \n",
    "    if condition == 'below':\n",
    "        df_out = df.loc[df[col] > filter_val]\n",
    "    elif condition == 'above':\n",
    "        df_out = df.loc[df[col] < filter_val]\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c284e",
   "metadata": {},
   "source": [
    "# Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfc682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THE BELOW to add the file path to the raw data\n",
    "input_file_path = r\"C:\\Users\\Lenovo\\Documents\\raw_data.csv\"\n",
    "raw_data = pd.read_csv(input_file_path, sep=',')\n",
    "\n",
    "# Add the file path to the ID list (must have columns named meterId and account_id)\n",
    "input_file_path = r\"C:\\Users\\Lenovo\\Documents\\id_list.csv\"\n",
    "id_list = pd.read_csv(input_file_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6544e36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "# Reduce the raw data\n",
    "raw_data_r = reduce_columns(raw_data)\n",
    "raw_data_g = group_data(raw_data_r)\n",
    "raw_data_s = smooth_data(raw_data_g)\n",
    "\n",
    "# Process the events list. Adjust the \"minutes\" parameter to suit the project needs. \n",
    "events_list = calculate_events(raw_data_s, minutes = 15)\n",
    "\n",
    "# Small correction scripts. Use data_quality_control(events_list, mode=\"conservative\") to minimize the effects.\n",
    "data_quality = data_quality_check(events_list)\n",
    "events_list_q = data_quality_control(events_list, limit = 0.3)\n",
    "data_quality_q = data_quality_check(events_list_q)\n",
    "# The unaccounted energy will be the energy that is not included in any events (energy gaps greater than the limit)\n",
    "\n",
    "# Adjust the time\n",
    "events_list_t = adjust_time(events_list_q, hours = 3)\n",
    "events_list_f = add_meterIds(events_list_t, id_list)\n",
    "raw_data_r_f = add_meterIds(raw_data_r, id_list)\n",
    "time_end = time.time()\n",
    "print(\"Complete. Total time = \" + str(time_end - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the events\n",
    "# Adjust the parameters as necessary.\n",
    "events_list_f_f = filter_events(events_list_f, filter_type = 'time', condition = 'below', filter_val = \"00:06:00\")\n",
    "events_list_f_f = filter_events(events_list_f_f, filter_type = 'energy', condition = 'below', filter_val = \"0.02\")\n",
    "events_list_f_f = filter_events(events_list_f_f, filter_type = 'power', condition = 'below', filter_val = \"0.2\")\n",
    "events_list_f_f = filter_events(events_list_f_f, filter_type = 'power', condition = 'above', filter_val = \"2.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b4de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the filtered output\n",
    "events_list_f_f.to_csv(r\"C:\\Users\\Lenovo\\Documents\\example_f_f.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
